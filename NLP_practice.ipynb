{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zesAeLHbcMy8",
        "outputId": "c1fc15df-620b-4510-e714-aea4f15faa6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Tokenization"
      ],
      "metadata": {
        "id": "wQp2VJZukNBO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVZq7moNdDvn",
        "outputId": "1af8f90d-c0c8-4346-dfef-68644bf579b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "corpus = \"\"\"My name is Sachin. This gem is your's to take, use and keep\n",
        "How are you?\"\"\"\n",
        "\n",
        "sentences = sent_tokenize(corpus)\n",
        "print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofQm6E5-cRy_",
        "outputId": "76e9d609-7804-4c66-c051-baecfe686d9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['My name is Sachin.', \"This gem is your's to take, use and keep \\nHow are you?\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = []\n",
        "for sentence in sentences:\n",
        "  words += word_tokenize(sentence)\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHK0uXlVc7GM",
        "outputId": "f75ced95-e0b5-4046-eaed-5d141b20c704"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['My', 'name', 'is', 'Sachin', '.', 'This', 'gem', 'is', 'your', \"'s\", 'to', 'take', ',', 'use', 'and', 'keep', 'How', 'are', 'you', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokenize(corpus) == words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSUF-e-5d5F3",
        "outputId": "c6ea80e5-ae23-4ae9-b65b-c02c8471ddfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import wordpunct_tokenize\n",
        "\n",
        "wordpunct_tokenize(corpus)   # Treats punctuations like .,?' are seperate tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClTIcxEvgYZ-",
        "outputId": "63bf6697-a9c0-483b-a24f-aaf03907d6f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['My',\n",
              " 'name',\n",
              " 'is',\n",
              " 'Sachin',\n",
              " '.',\n",
              " 'This',\n",
              " 'gem',\n",
              " 'is',\n",
              " 'your',\n",
              " \"'\",\n",
              " 's',\n",
              " 'to',\n",
              " 'take',\n",
              " ',',\n",
              " 'use',\n",
              " 'and',\n",
              " 'keep',\n",
              " 'How',\n",
              " 'are',\n",
              " 'you',\n",
              " '?']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "\n",
        "corpus2 = \"I am Sachin. This your's to take, use. Don't steal it,they'll arrest you\"\n",
        "\n",
        "tokenizer = TreebankWordTokenizer()\n",
        "tokenizer.tokenize(corpus2) # It treats . at the the end of sentence as part of that sentence. It can seperate contractions like don't, they'll etc."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHP2TwEWg-6T",
        "outputId": "ce5b7ccd-9fb7-49c0-808a-6a679fabcd35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I',\n",
              " 'am',\n",
              " 'Sachin.',\n",
              " 'This',\n",
              " 'your',\n",
              " \"'s\",\n",
              " 'to',\n",
              " 'take',\n",
              " ',',\n",
              " 'use.',\n",
              " 'Do',\n",
              " \"n't\",\n",
              " 'steal',\n",
              " 'it',\n",
              " ',',\n",
              " 'they',\n",
              " \"'ll\",\n",
              " 'arrest',\n",
              " 'you']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "tokenizer = RegexpTokenizer(r\"[\\w']+\")\n",
        "tokenizer.tokenize(corpus2) # Keeps all words and digits(and ' as part of words) but not symbols"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bg6Dggamhrtn",
        "outputId": "59c64718-15c4-462d-c5e7-22c188fcec9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I',\n",
              " 'am',\n",
              " 'Sachin',\n",
              " 'This',\n",
              " \"your's\",\n",
              " 'to',\n",
              " 'take',\n",
              " 'use',\n",
              " \"Don't\",\n",
              " 'steal',\n",
              " 'it',\n",
              " \"they'll\",\n",
              " 'arrest',\n",
              " 'you']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stemming"
      ],
      "metadata": {
        "id": "3esd8KGQkIeX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word stems include prefix, suffix, and root of the word known as Lemma. Stemming chops off prefix, and suffix leaving behind only root of the word."
      ],
      "metadata": {
        "id": "n1R8_iS7ljVu"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c35b719"
      },
      "source": [
        "Stemming is like chopping off the ends of words to get to their basic form. For example, \"playing,\" \"played,\" and \"plays\" all get reduced to \"play.\" This basic form isn't always a real word, and it's different from a \"lemma,\" which is the accurate dictionary form of a word."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "stemmer = PorterStemmer()  #Very simple but does lot of mistakes\n",
        "stemmer.stem('playing')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "aY37vU6Ejbe1",
        "outputId": "167a3901-fa0b-4008-e094-e48fd98b30a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'play'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in [\"played\", \"playing\", \"plays\",\"player\"]:\n",
        "  print(stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xPYyNA5lKfk",
        "outputId": "d6d1f04c-dfa0-40be-ffb3-c6b4673145f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "play\n",
            "play\n",
            "play\n",
            "player\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "stemmer = SnowballStemmer(language='english') # Takes param 'language compulsorily and better than PorterStemmer\n",
        "\n",
        "for word in [\"played\", \"playing\", \"plays\",\"player\"]:\n",
        "  print(stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNS8Tl9clU_K",
        "outputId": "4509c50a-de00-4802-a74f-ed03e5fca9f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "play\n",
            "play\n",
            "play\n",
            "player\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import RegexpStemmer\n",
        "\n",
        "stemmer = RegexpStemmer(\"ing$|s$|e$|able$|y$\", min=4) #If it ends with such prefixes remove them\n",
        "for word in [\"played\", \"playing\", \"plays\",\"player\"]:\n",
        "  print(stemmer.stem(word))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2N9-OytnkeX",
        "outputId": "643989ad-e1ba-4ced-b7a2-f56ed71dc7f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "played\n",
            "play\n",
            "play\n",
            "player\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aab0799",
        "outputId": "8802b151-5ff7-457b-8a6c-d7df0da757f3"
      },
      "source": [
        "from nltk.stem import PorterStemmer, SnowballStemmer, RegexpStemmer\n",
        "\n",
        "porter_stemmer = PorterStemmer()\n",
        "snowball_stemmer = SnowballStemmer('english')\n",
        "regexp_stemmer = RegexpStemmer(\"ing$|s$|e$|able$|y$\", min=4)\n",
        "\n",
        "words_to_stem = [\"universal\", \"universality\", \"universe\", \"universem\",\n",
        "                 \"generous\", \"generously\", \"generosity\",\n",
        "                 \"beautiful\", \"beautifully\", \"beauty\"]\n",
        "\n",
        "print(\"Porter Stemmer Output:\")\n",
        "for word in words_to_stem:\n",
        "  print(f\"{word} -> {porter_stemmer.stem(word)}\")\n",
        "\n",
        "print(\"\\nSnowball Stemmer Output:\")\n",
        "for word in words_to_stem:\n",
        "  print(f\"{word} -> {snowball_stemmer.stem(word)}\")\n",
        "\n",
        "print(\"\\nRegexp Stemmer Output:\")\n",
        "for word in words_to_stem:\n",
        "  print(f\"{word} -> {regexp_stemmer.stem(word)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Porter Stemmer Output:\n",
            "universal -> univers\n",
            "universality -> univers\n",
            "universe -> univers\n",
            "universem -> universem\n",
            "generous -> gener\n",
            "generously -> gener\n",
            "generosity -> generos\n",
            "beautiful -> beauti\n",
            "beautifully -> beauti\n",
            "beauty -> beauti\n",
            "\n",
            "Snowball Stemmer Output:\n",
            "universal -> univers\n",
            "universality -> univers\n",
            "universe -> univers\n",
            "universem -> universem\n",
            "generous -> generous\n",
            "generously -> generous\n",
            "generosity -> generos\n",
            "beautiful -> beauti\n",
            "beautifully -> beauti\n",
            "beauty -> beauti\n",
            "\n",
            "Regexp Stemmer Output:\n",
            "universal -> universal\n",
            "universality -> universalit\n",
            "universe -> univers\n",
            "universem -> universem\n",
            "generous -> generou\n",
            "generously -> generousl\n",
            "generosity -> generosit\n",
            "beautiful -> beautiful\n",
            "beautifully -> beautifull\n",
            "beauty -> beaut\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lemmatization"
      ],
      "metadata": {
        "id": "6pkwzyiHova3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To solve the issue of stemming which gives incorrect words, lemmatization is used.\n",
        "The root word that is obtained is called lemma, and is always a valid word in the dictionary. Hence lemmatization is realiable and important."
      ],
      "metadata": {
        "id": "h9676xEto0R-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **WordNetLemmatizer**"
      ],
      "metadata": {
        "id": "TKxWAOwapyAP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d9292a2"
      },
      "source": [
        "WordNet is a large dictionary with a vast number of English words and their relationships. It organizes words into sets of synonyms, called **synonym sets (synsets)**. Each synset represents a distinct concept and can include multiple words that have similar meanings. WordNet also provides short definitions and examples for each synset. Such dictionaries, like WordNet, are used as a knowledge base in lemmatization to find the correct base form of a word based on its meaning and context."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0df3ff19"
      },
      "source": [
        "\n",
        "This lemmatizer uses WordNet, a large dictionary of English words and their relationships. It helps find the base form (lemma) of a word, like changing \"running\" to \"run,\" by looking it up in WordNet and considering if it's a noun, verb, etc."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QACSe4bpsp9H",
        "outputId": "9508a843-8f47-4152-a692-3dd024d48602"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet\n",
        "\n",
        "wordnet.synsets(\"playing\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiOs4TLBnBSk",
        "outputId": "ef20c626-5119-4673-8290-06fc4917daa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('playing.n.01'),\n",
              " Synset('playing.n.02'),\n",
              " Synset('acting.n.01'),\n",
              " Synset('play.v.01'),\n",
              " Synset('play.v.02'),\n",
              " Synset('play.v.03'),\n",
              " Synset('act.v.03'),\n",
              " Synset('play.v.05'),\n",
              " Synset('play.v.06'),\n",
              " Synset('play.v.07'),\n",
              " Synset('act.v.05'),\n",
              " Synset('play.v.09'),\n",
              " Synset('play.v.10'),\n",
              " Synset('play.v.11'),\n",
              " Synset('play.v.12'),\n",
              " Synset('play.v.13'),\n",
              " Synset('play.v.14'),\n",
              " Synset('play.v.15'),\n",
              " Synset('play.v.16'),\n",
              " Synset('play.v.17'),\n",
              " Synset('play.v.18'),\n",
              " Synset('toy.v.02'),\n",
              " Synset('play.v.20'),\n",
              " Synset('dally.v.04'),\n",
              " Synset('play.v.22'),\n",
              " Synset('dally.v.01'),\n",
              " Synset('play.v.24'),\n",
              " Synset('act.v.10'),\n",
              " Synset('play.v.26'),\n",
              " Synset('bring.v.03'),\n",
              " Synset('play.v.28'),\n",
              " Synset('play.v.29'),\n",
              " Synset('bet.v.02'),\n",
              " Synset('play.v.31'),\n",
              " Synset('play.v.32'),\n",
              " Synset('play.v.33'),\n",
              " Synset('meet.v.10'),\n",
              " Synset('play.v.35')]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**WordNet.morphy()**"
      ],
      "metadata": {
        "id": "gGdoqsfv0e9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"playing\", \"played\", \"plays\", \"player\"]\n",
        "\n",
        "for word in words:\n",
        "  print(wordnet.morphy(word))  # WordNetLemmatizer is actually a wrapper around wordnet, which uses this morphy() under the hood."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFfTkCYCsg_i",
        "outputId": "cf448cb4-b9b2-472d-d81d-a6720b895b61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "playing\n",
            "play\n",
            "play\n",
            "player\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "for word in words:\n",
        "  print(lemmatizer.lemmatize(word)) # We can see that Lemmatizer still has a bit different output than the morphy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HH7wgKs0AVh",
        "outputId": "01ee0ed1-4ecc-4312-afd7-6132c710dcb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "playing\n",
            "played\n",
            "play\n",
            "player\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We can give \"pos\" arg which specifies to also give that word's \"Parts of Speech\"(POS) Tag\n",
        "print(lemmatizer.lemmatize(\"playing\", pos=\"v\")) # give a lemma that is a verb of the given word\n",
        "print(lemmatizer.lemmatize(\"playing\", pos=\"n\")) # give a lemma that is a noun of the given word\n",
        "print(lemmatizer.lemmatize(\"playing\", pos=\"a\")) # give a lemma that is a adjective of the given word\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgK79Yh60QkA",
        "outputId": "c03d5806-ee3d-4fec-8159-a6f94d91fe51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "play\n",
            "playing\n",
            "playing\n",
            "playing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parts of Speech"
      ],
      "metadata": {
        "id": "dzmnvdKc2VZf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "548a2a1e"
      },
      "source": [
        "Here are some common parts of speech with examples and their corresponding tags used in NLTK:\n",
        "\n",
        "*   **Noun (N):** Represents a person, place, thing, or idea.\n",
        "    *   Examples: `cat`, `city`, `book`, `happiness`\n",
        "    *   Tags: `NN` (singular noun), `NNS` (plural noun), `NNP` (proper noun singular), `NNPS` (proper noun plural)\n",
        "\n",
        "*   **Verb (V):** Describes an action or a state of being.\n",
        "    *   Examples: `run`, `eat`, `is`, `believe`\n",
        "    *   Tags: `VB` (verb base form), `VBD` (verb past tense), `VBG` (verb present participle), `VBN` (verb past participle), `VBP` (verb non-3rd person singular present), `VBZ` (verb 3rd person singular present)\n",
        "\n",
        "*   **Adjective (A):** Describes or Modifies a noun or pronoun.\n",
        "    *   Examples: `happy`, `big`, `red`, `interesting`\n",
        "    *   Tags: `JJ` (adjective or numeral, ordinal), `JJR` (adjective comparative), `JJS` (adjective superlative)\n",
        "\n",
        "*   **Adverb (R):** Describes or Modifies a verb, adjective, or other adverb.\n",
        "    *   Examples: `quickly`, `very`, `happily`, `well`\n",
        "    *   Tags: `RB` (adverb), `RBR` (adverb comparative), `RBS` (adverb superlative)\n",
        "\n",
        "*   **Pronoun (PRP):** A generalization of a noun without specific names .\n",
        "    *   Examples: `he`, `she`, `it`, `they`, `I`\n",
        "    *   Tags: `PRP` (personal pronoun), `PRP$` (possessive pronoun)\n",
        "\n",
        "*   **Preposition (P):** Shows the relationship between a noun or pronoun and another word in the sentence.\n",
        "    *   Examples: `on`, `in`, `at`, `by`, `with`, `under`\n",
        "    *   Tags: `IN` (preposition or conjunction, subordinating)\n",
        "\n",
        "*   **Conjunction (C):** Connects words, phrases, or clauses.\n",
        "    *   Examples: `and`, `but`, `or`, `for`\n",
        "    *   Tags: `CC` (coordinating conjunction)\n",
        "\n",
        "*   **Determiner (D):** Comes before a noun to specify its quantity or to clarify what it refers to.\n",
        "    *   Examples: `the`, `a`, `an`, `this`, `that`\n",
        "    *   Tags: `DT` (determiner)\n",
        "\n",
        "*   **Interjection (UH):** Expresses strong emotion.\n",
        "    *   Examples: `Oh!`, `Wow!`, `Hey!`\n",
        "    *   Tags: `UH` (interjection)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PoS Tagging in NLTK"
      ],
      "metadata": {
        "id": "pSqGwIPt3XSH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEITAJC03_BA",
        "outputId": "80b9d864-a0da-44cb-f7d9-ecb3726b9ca1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "tags = nltk.pos_tag([\"playing\"]) # It takes list of strings not str, since its expected to be used after word tokenizers\n",
        "print(tags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mImWZQy01k20",
        "outputId": "b969f03b-7836-4c97-e6a7-ea7a1c12ebf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('playing', 'VBG')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"play\",\"playing\", \"played\", \"been\", \"red\",\"gleefully\",\"on\",\"and\",\"this\"]\n",
        "\n",
        "# for word in words:\n",
        "#   print(nltk.pos_tag([word])) # or simply\n",
        "\n",
        "nltk.pos_tag(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRvewk9P3kmb",
        "outputId": "cc239222-7941-4cdb-ff5f-f221da1c465f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('play', 'NN'),\n",
              " ('playing', 'VBG'),\n",
              " ('played', 'VBD'),\n",
              " ('been', 'VBN'),\n",
              " ('red', 'JJ'),\n",
              " ('gleefully', 'RB'),\n",
              " ('on', 'IN'),\n",
              " ('and', 'CC'),\n",
              " ('this', 'DT')]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**: the result of pos tag is list of tuples, Hence to get tag of each word use double indexing tag[word_index][1]"
      ],
      "metadata": {
        "id": "b_C2dSaS5y4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ex : Find all the words that are verbs or noun\n",
        "tags = nltk.pos_tag(words)\n",
        "verb_codes = [\"NN\",\"VBG\" ]\n",
        "\n",
        "for i in range(len(words)):\n",
        "  if tags[i][1] in verb_codes:\n",
        "    print(words[i],\"=>\",tags[i][1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_Xro8VU4op-",
        "outputId": "175dbe56-5c80-4d8e-ada3-f325b8520204"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "play => NN\n",
            "playing => VBG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eJCQPfxq8NiR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}